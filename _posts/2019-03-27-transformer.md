---
title: 关于transformer结构的一些小Tips
layout: post
categories: NLP
tags: NLP 算法
excerpt: 关于transformer的详细图文详解教程
---
#### Transformer来源
Transformer是谷歌在2017年做机器翻译任务的**“Attention is all you need”**的论文中提出的，Transformer的结构包含两部分：Encoder和Decoder。Encoder是六层编码器首位相连堆砌而成，Decoder也是六层解码器堆成的。其结构如下：
![Image Title](https://i.loli.net/2019/03/27/5c9b3779d79b9.png)

详细的结构图如：
![Image Title](https://i.loli.net/2019/03/27/5c9b370ec551f.jpg)

#### Transformer结构






#### 参考

[放弃幻想，全面拥抱Transformer：自然语言处理三大特征抽取器（CNN/RNN/TF）比较](https://zhuanlan.zhihu.com/p/54743941)

[从Seq2seq到Attention模型到Self Attention（二）](https://wallstreetcn.com/articles/3417279)
